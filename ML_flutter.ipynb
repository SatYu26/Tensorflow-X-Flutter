{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML-flutter.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EI8bUwgzIFr0"
      },
      "source": [
        "!pip install -q kaggle\r\n",
        "!pip install -q kaggle-cli\r\n",
        "!mkdir -p ~/.kaggle\r\n",
        "!cp \"/content/drive/MyDrive/Colab Notebooks/kaggle.json\" ~/.kaggle/\r\n",
        "!cat ~/.kaggle/kaggle.json \r\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bgTirYYIM2j",
        "outputId": "5a3d3516-44c8-4de5-89c1-49e9e2aa7451"
      },
      "source": [
        "cd /content/drive/MyDrive/Projects/MLxFlutter\r\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Projects/MLxFlutter\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8oB3o4THN1E"
      },
      "source": [
        "!kaggle datasets download -d kritikseth/fruit-and-vegetable-image-recognition\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpbKTnF6Idoa"
      },
      "source": [
        "!unzip /content/drive/MyDrive/Projects/MLxFlutter/fruit-and-vegetable-image-recognition.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rc7rsBoXIgUC"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import os\r\n",
        "base_dir = '/content/drive/MyDrive/Projects/MLxFlutter/train'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWbrSzAuJ0DX",
        "outputId": "97d185de-fd32-4756-aab9-4162e7828e70"
      },
      "source": [
        "#now we will do some preprocessing, i.e we are preparing the raw data to make it suitable for a building and training models\r\n",
        "\r\n",
        "IMAGE_SIZE = 224 #image size that we are going to set the images in the dataset to.\r\n",
        "BATCH_SIZE = 64 #the number of images we are inputting into the neural network at once.\r\n",
        "\r\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator( #preprocessing our image\r\n",
        "    rescale = 1./255, #firstly, rescaling it to 1/255 which will make the file size smaller, hence reducing the training time\r\n",
        "    validation_split=0.2 #secondly, normally a dataset has a test set and a training set, \r\n",
        "    #validation set is normally to test our neural network,which would give us a measure of accuracy on how well the neural network will do on the predictions.\r\n",
        "    #here we are telling keras to use 20% for validation and 80% training\r\n",
        ")\r\n",
        "\r\n",
        "train_generator = datagen.flow_from_directory( #training generator\r\n",
        "    base_dir, #the directory having the fruits and vegetable photos\r\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),  #converting images to 224 by 224\r\n",
        "    batch_size = BATCH_SIZE, #images getting inputed into the neural network through each epoch or each step\r\n",
        "    subset='training' #the name we will call it\r\n",
        ")\r\n",
        "val_generator = datagen.flow_from_directory(  #validation generator\r\n",
        "    base_dir, \r\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\r\n",
        "    batch_size=BATCH_SIZE,\r\n",
        "    subset='validation'\r\n",
        ")\r\n",
        "#So as we can see from below, our training generator dataset 2872 images and the validation generator dataset has 709 images"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2872 images belonging to 36 classes.\n",
            "Found 709 images belonging to 36 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SiOWzJvEK_6C",
        "outputId": "7dfd065c-3467-49ae-980c-a4ce86a54d9f"
      },
      "source": [
        "#Next we have to create a labels.txt file that will hold all our labels (important for Flutter)\r\n",
        "print(train_generator.class_indices) #prints every single key and class of that dataset\r\n",
        "labels = '\\n'.join(sorted(train_generator.class_indices.keys())) #print all these keys as a list of labels into a text file called labels.txt\r\n",
        "with open('labels.txt', 'w') as f: #writes to the labels.txt file, and if it doesnt exists, it creates one, and if it does exist, it will overrite it. (thats what 'w' is for)\r\n",
        "    f.write(labels)\r\n",
        "\r\n",
        "#preprocessing of raw data is hence complete and now its time to build our neural network"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'apple': 0, 'banana': 1, 'beetroot': 2, 'bell pepper': 3, 'cabbage': 4, 'capsicum': 5, 'carrot': 6, 'cauliflower': 7, 'chilli pepper': 8, 'corn': 9, 'cucumber': 10, 'eggplant': 11, 'garlic': 12, 'ginger': 13, 'grapes': 14, 'jalepeno': 15, 'kiwi': 16, 'lemon': 17, 'lettuce': 18, 'mango': 19, 'onion': 20, 'orange': 21, 'paprika': 22, 'pear': 23, 'peas': 24, 'pineapple': 25, 'pomegranate': 26, 'potato': 27, 'raddish': 28, 'soy beans': 29, 'spinach': 30, 'sweetcorn': 31, 'sweetpotato': 32, 'tomato': 33, 'turnip': 34, 'watermelon': 35}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cgjk1MS6MJ9p",
        "outputId": "6e34d72c-da15-4009-9b3e-c7a253a8360d"
      },
      "source": [
        "#building a neural network using transfer learning method where we take a pretrained neural network called MobileNetV2 which is a convolutional neural network architecture that seeks to perform well on mobile devices and can predict up to 80 different classes\r\n",
        "#we are going to have a base model on top of which we are going to add pre trained neural network to have it predict the classes we want\r\n",
        "IMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3) \r\n",
        "base_model = tf.keras.applications.MobileNetV2( #grabbing pretrained neural network of choice\r\n",
        "    input_shape=IMG_SHAPE,\r\n",
        "    include_top=False, #this will freeze all the weights, because we dont have to retrain and change the weights, instead just add on to the MobileNetV2 CNN, so it clasiffies 5 classes instead of 80\r\n",
        "    weights='imagenet'\r\n",
        ")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jSao3X1NJJM"
      },
      "source": [
        "base_model.trainable=False #this freezes all the neurons for our base model\r\n",
        "model = tf.keras.Sequential([ #neural networks act in a sequence of layers, so we add layers as we want\r\n",
        "  base_model,\r\n",
        "  tf.keras.layers.Conv2D(32,3, activation = 'relu'), #This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs. Bascially, it trying to understand the patterns of the image\r\n",
        "  tf.keras.layers.Dropout(0.2), #This layer prevents Neural Networks from Overfitting, i.e being too precise to a point where the NN is only able to recognize images that are present in the dataset\r\n",
        "  tf.keras.layers.GlobalAveragePooling2D(), #This layer calculates the average output of each feature map in the previous layer, thus reducing the data significantly and preparing the model for the final layer\r\n",
        "  tf.keras.layers.Dense(36, #no.of classes\r\n",
        "                        activation='softmax')\r\n",
        "])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cg5xjwV4OHTM"
      },
      "source": [
        "model.compile(\r\n",
        "    optimizer=tf.keras.optimizers.Adam(), #Adam is a popular optimiser, designed specifically for training deep neural networks\r\n",
        "    loss='categorical_crossentropy', \r\n",
        "    metrics=['accuracy']\r\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jj6RTH0yOhbc",
        "outputId": "6f02c9a2-89d7-47ab-8ce4-62d6d541823b"
      },
      "source": [
        "epochs = 10 #higher the epochs, more accurate is the NN, however it could cause Overfitting, if too high\r\n",
        "history = model.fit(\r\n",
        "    train_generator, \r\n",
        "    epochs = epochs, \r\n",
        "    validation_data=val_generator\r\n",
        ")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 4/45 [=>............................] - ETA: 1:00 - loss: 4.0371 - accuracy: 0.0316"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "45/45 [==============================] - 148s 3s/step - loss: 3.2600 - accuracy: 0.1279 - val_loss: 2.0373 - val_accuracy: 0.3977\n",
            "Epoch 2/10\n",
            "45/45 [==============================] - 130s 3s/step - loss: 1.8133 - accuracy: 0.4960 - val_loss: 1.2164 - val_accuracy: 0.6389\n",
            "Epoch 3/10\n",
            "45/45 [==============================] - 129s 3s/step - loss: 1.0058 - accuracy: 0.7269 - val_loss: 0.9552 - val_accuracy: 0.7348\n",
            "Epoch 4/10\n",
            "45/45 [==============================] - 128s 3s/step - loss: 0.6263 - accuracy: 0.8290 - val_loss: 0.7774 - val_accuracy: 0.7616\n",
            "Epoch 5/10\n",
            "45/45 [==============================] - 128s 3s/step - loss: 0.3977 - accuracy: 0.8902 - val_loss: 0.7654 - val_accuracy: 0.7687\n",
            "Epoch 6/10\n",
            "45/45 [==============================] - 128s 3s/step - loss: 0.2834 - accuracy: 0.9226 - val_loss: 0.7858 - val_accuracy: 0.7546\n",
            "Epoch 7/10\n",
            "45/45 [==============================] - 128s 3s/step - loss: 0.1948 - accuracy: 0.9529 - val_loss: 0.7991 - val_accuracy: 0.7616\n",
            "Epoch 8/10\n",
            "45/45 [==============================] - 128s 3s/step - loss: 0.1429 - accuracy: 0.9693 - val_loss: 0.7888 - val_accuracy: 0.7630\n",
            "Epoch 9/10\n",
            "45/45 [==============================] - 129s 3s/step - loss: 0.1037 - accuracy: 0.9832 - val_loss: 0.8244 - val_accuracy: 0.7574\n",
            "Epoch 10/10\n",
            "45/45 [==============================] - 128s 3s/step - loss: 0.0797 - accuracy: 0.9893 - val_loss: 0.7835 - val_accuracy: 0.7743\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_9i3iN4OtOE",
        "outputId": "a60fb830-1feb-45b0-fc28-e68c732834ac"
      },
      "source": [
        "#now that we have our neural network trained with tensorflow and keras, we can export it \r\n",
        "saved_model_dir = '' #means current directory\r\n",
        "tf.saved_model.save(model, saved_model_dir) #saves to the current directory\r\n",
        "\r\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir) \r\n",
        "tflite_model = converter.convert() #converts our model into a .tflite model which flutter uses for ondevice machine learning\r\n",
        "\r\n",
        "with open('model.tflite', 'wb') as f: #to write the converted model into a file, written as binary so add 'wb' instead of 'w'\r\n",
        "  f.write(tflite_model)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "7ylloB_yOt4D",
        "outputId": "82ed0ea8-5db5-4f04-c072-a63f0975d2e8"
      },
      "source": [
        "#use below codes to download files locally if using google colab\r\n",
        "from google.colab import files\r\n",
        "files.download('model.tflite')\r\n",
        "files.download('labels.txt')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_c5357e35-35a9-4637-9f87-e88a638f50b1\", \"model.tflite\", 10380956)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_96b0ec45-0227-4e84-b3e6-04af76504176\", \"labels.txt\", 294)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}